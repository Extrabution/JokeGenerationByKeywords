{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f38ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2054d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "https://www.theonion.com/opinion/american-voices?startIndex=20\n"
     ]
    }
   ],
   "source": [
    "# create list of index page links to later download\n",
    "# example links\n",
    "link = \"https://www.theonion.com/opinion/american-voices\"\n",
    "link2 = \"https://www.theonion.com/opinion/american-voices?startIndex=20\"\n",
    "\n",
    "index_links = []\n",
    "\n",
    "article_n = 6500 # amount of articles\n",
    "articles_per_page = 20\n",
    "index_n = int(article_n/articles_per_page) # amount of index pages\n",
    "\n",
    "for i in range(index_n):\n",
    "    index_links.append(link + \"?startIndex=\" + str(i * articles_per_page))\n",
    "\n",
    "print(len(index_links))\n",
    "print(index_links[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be9c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pages_file = \"index_pages.txt\"\n",
    "index_pages = [] # HTML content of index pages\n",
    " \n",
    "if os.path.isfile(index_pages_file): \n",
    "    with open(index_pages_file, 'rb') as f:\n",
    "        content = f.read()\n",
    "        index_pages = pickle.loads(content)\n",
    "        print(\"loaded pickled file\")\n",
    "        print(len(index_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb91edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for i in range(len(index_pages), len(index_links)):\n",
    "        print(i)\n",
    "        index_link = index_links[i]\n",
    "        index_pages.append(requests.get(index_link).text) \n",
    "except:\n",
    "    pass\n",
    "serialized = pickle.dumps(index_pages) \n",
    "with open(index_pages_file, 'wb') as f:\n",
    "    f.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e91be49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_links = []\n",
    "\n",
    "for i in range(len(index_pages)):\n",
    "    html = index_pages[i]\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    soup_a =  soup.find_all('article')\n",
    "    for i in soup_a:\n",
    "        article_links.append( i.find('a', class_='sc-1out364-0 dPMosf js_link')['href'] )\n",
    "\n",
    "len(article_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b675c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_htmls_file = \"article_htmls.txt\"\n",
    "article_htmls = [] # HTML content of index pages\n",
    " \n",
    "if os.path.isfile(article_htmls_file): \n",
    "    with open(article_htmls_file, 'rb') as f:\n",
    "        content = f.read()\n",
    "        article_htmls = pickle.loads(content)\n",
    "        print(\"loaded pickled file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b5bfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "article_htmls_file = \"article_htmls.txt\"\n",
    "try:\n",
    "    for i in range(len(article_htmls), len(article_links)):\n",
    "        link = article_links[i]\n",
    "        article_htmls.append(requests.get(link).text) \n",
    "        print(i)\n",
    "        #time.sleep(0.5)\n",
    "except:\n",
    "    pass\n",
    "serialized = pickle.dumps(article_htmls) \n",
    "with open(article_htmls_file, 'wb') as f:\n",
    "    f.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1bd399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pickled file\n",
      "6495\n"
     ]
    }
   ],
   "source": [
    "article_texts_file = \"article_texts.txt\"\n",
    "article_texts = [] # Filtered article contents\n",
    " \n",
    "if os.path.isfile(article_texts_file): \n",
    "    with open(article_texts_file, 'rb') as f:\n",
    "        content = f.read()\n",
    "        article_texts = pickle.loads(content)\n",
    "        print(\"loaded pickled file\")\n",
    "        print(len(article_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea68cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for i in range(len(article_texts), len(article_texts)):\n",
    "        try:\n",
    "            html = article_htmls[i]\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            header =  soup.find('header', class_=\"sc-1efpnfq-1 blDizU\").text\n",
    "            subtitle = soup.find('p', class_=\"sc-77igqf-0 fnnahv\").text\n",
    "\n",
    "            comments = soup.find_all('div', class_=\"sc-q35npn-1 dGOWqB\") \n",
    "            comments_text = [ x.find('p', class_=\"sc-q35npn-3 cKacox\").text for x in comments ]\n",
    "            comments_names = [ x.find('p', class_=\"sc-q35npn-4 bfrXyU\").text for x in comments ]\n",
    "\n",
    "            comments_zipped = list(zip(comments_text, comments_names))\n",
    "\n",
    "            article_texts.append([header, subtitle, comments_zipped])\n",
    "        except AttributeError as err: \n",
    "            print(f\"Attribute Error at {i}\")\n",
    "except KeyboardInterrupt as err:\n",
    "    pass\n",
    "serialized = pickle.dumps(article_texts) \n",
    "with open(article_texts_file, 'wb') as f:\n",
    "    f.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8227a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6495\n",
      "['SpaceX Starship Blows Up Minutes After Launch', 'SpaceX’s Starship rocket, the most powerful ever built, blasted off on an unpiloted maiden flight Thursday, flying for more than two minutes before exploding. What do you think?', [('“Everything explodes eventually.”', 'Kat Alvarez, Apartment Stager'), ('“We’re on the doorstep of a bold new era of space disasters.”', 'Andy Hood, Jar Sealer'), ('“I’d like to see China blow up a rocket in less than two minutes.”', 'Oscar Huerta, PR Educator')]]\n",
      "['Study Finds Plants Make Noises When Stressed', 'A new study has found that “stressed” plants that have not been watered for several days or had their stems cut emit ultrasonic clicking noises that are undetectable to the human ear but may be heard by insects and other animals. What do you think?', [('“Strange, mine just turn brown and die.”', 'Tracey Puentes, Monologue Editor'), ('“They should suffer in silence like the rest of us.”', 'Isaac McCafferty, Chief Consultant'), ('“Nothing a little overwatering can’t fix.”', 'Neil Leary, Pan Greaser')]]\n",
      "['New Zealand Prime Minister Resigns Citing Burnout', 'New Zealand Prime Minister Jacinda Ardern, who gained international praise for her adept response to the nation’s worst mass shooting and pandemic, will step down, saying she no longer had “enough in the tank” to do the job justice. What do you think?', [('“Why is she so stressed? It’s just New Zealand.”', 'Justin Nicols, Snack Historian'), ('“She wouldn’t cut it in America, where our leaders can tolerate multiple mass shootings.”', 'Adolfo Lopez, Consumer Watchdog'), ('“I thought it was a politician’s job to cling to power well past senility.”', 'Ali Blau, Interpreter')]]\n",
      "['Beloved Children’s Author Beverly Cleary Dies At 104', 'Celebrated children’s author Beverly Cleary, one of America’s most successful writers with 91 million books sold worldwide and best known for her Ramona Quimby series, has died at 104. What do you think?', [('“Her books are part of the reason I ride a tiny motorcycle.”', 'Josh Sutton • Paper Pulper'), ('“No! Not before we get Ramona Quimby, Age 104!”', ' Les Gregory • Systems Analyst'), ('“I have such fond memories of pretending to read her books as a kid.”', 'June Lucas • Financial Seer')]]\n",
      "['Social Media Overtakes Newspapers As Source Of News', 'A new Pew study found that for the first time, more Americans get their news from social media than newspapers. What do you think?', [('“Right, I remember reading about this on Instagram.”', 'Nick Villa • Dromedary Wrangler'), ('“No wonder everybody’s so informed!”', 'Jameson Wilder • Pencil Industry Disrupter'), ('“As long as the people reading it on TV still get it from newspapers, we’ll be fine.”', 'Jessica Hyde • Unit Standardizer')]]\n",
      "['First Ever Male CoverGirl Model Announced', 'James Charles, a 17-year-old famous on social media for his elaborate makeup designs, has been announced as the first ever male CoverGirl model. What do you think?', [('“I’m all for breaking down barriers, but I cannot stand successful teens.”', 'Mick Yount • Tortilla Presser'), ('“It’s about time the beauty industry subjected males to unattainable beauty standards.”', 'Stacey Beech • Lecture Auditor'), ('“How come nobody ever invites me to blaze any trails?”', 'Brent Koppel • Uplighting Specialist')]]\n",
      "['Disney Expanding ‘Star Wars’ Attractions At Theme Parks', 'With Star Wars: Episode VII in the works, Disney officials have announced that the company is planning to significantly expand Star Wars rides and attractions within its theme parks to coincide with the film’s planned premiere in late 2015. What do you think?', [('“Finally, a way to experience ‘Star Wars’ beyond the movies, books, TV shows, video games, action figures, clothing, fast food tie-ins, and currently existing theme park attractions.”', 'Brandon Murphy • Paper Shredder Supervisor'), ('“It’s a good way to get word out about the new films, but they should consider running a TV ad or some other campaign as well.”', 'Jeff Berger • Systems Analyst'), ('“The race is on to become the first patron banned from the Mos Eisley Cantina.”', 'Alyson Valmond • Buffet Planner')]]\n"
     ]
    }
   ],
   "source": [
    "print(len(article_texts))\n",
    "print(article_texts[0])\n",
    "print(article_texts[20])\n",
    "print(article_texts[100])\n",
    "print(article_texts[1000])\n",
    "print(article_texts[2000])\n",
    "print(article_texts[3000])\n",
    "print(article_texts[4000])\n",
    "#for i in range(30):\n",
    "    #print(article_texts[i])\n",
    "# print(article_texts[1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
