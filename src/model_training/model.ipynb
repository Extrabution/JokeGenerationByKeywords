{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "with open(\"../../data/article_texts.txt\",'rb') as f:\n",
    "    texts = pickle.load(f, encoding=\"UTF-8\")\n",
    "with open(\"../../data/english_anecs_list.pickle\", \"rb\") as f:\n",
    "    english_anecs_list = pickle.load(f, encoding=\"UTF-8\")\n",
    "with open(\"../../data/ids_to_labels.pickle\", \"rb\") as f:\n",
    "    ids_to_labels = pickle.load(f, encoding=\"utf-8\")\n",
    "with open(\"../../data/labels_to_ids.pickle\", \"rb\") as f:\n",
    "    labels_to_ids = pickle.load(f, encoding=\"utf-8\")\n",
    "with open(\"../../data/unique_labels.pickle\", \"rb\") as f:\n",
    "    unique_labels = pickle.load(f, encoding=\"UTF-8\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "3042"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_anecs_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "text = ['SpaceX Starship Blows Up Minutes After Launch',\n",
    " 'SpaceX’s Starship rocket, the most powerful ever built, blasted off on an unpiloted maiden flight Thursday, flying for more than two minutes before exploding. What do you think?']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(data:str):\n",
    "    inputs = tokenizer(data, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    return inputs\n",
    "def ids_to_tokens(text_input):\n",
    "    return tokenizer.convert_ids_to_tokens(text_input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dslim/bert-base-NER and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([17, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([17]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "class BertModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertModel, self).__init__()\n",
    "        self.bert = BertForTokenClassification.from_pretrained('dslim/bert-base-NER', num_labels=len(unique_labels),\n",
    "                                                               ignore_mismatched_sizes=True)\n",
    "\n",
    "    def forward(self, input_ids, label=None):\n",
    "        output = self.bert(labels=label, input_ids=input_ids, return_dict=False)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "model = BertModel()\n",
    "\n",
    "model.load_state_dict(torch.load('bert_trainedNEREnglish', map_location=torch.device('cpu')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'NPR', 'entity': 'O'}, {'word': 'plans', 'entity': 'B-org'}, {'word': 'to', 'entity': 'B-org'}, {'word': 'shut', 'entity': 'O'}, {'word': 'down', 'entity': 'O'}, {'word': 'its', 'entity': 'O'}, {'word': 'official', 'entity': 'O'}, {'word': 'Twitter', 'entity': 'O'}, {'word': 'accounts', 'entity': 'O'}, {'word': 'after', 'entity': 'B-org'}, {'word': 'the', 'entity': 'O'}, {'word': 'Elon', 'entity': 'O'}, {'word': 'Muskowned', 'entity': 'O'}, {'word': 'platform’s', 'entity': 'O'}, {'word': 'decision', 'entity': 'I-org'}, {'word': 'to', 'entity': 'I-org'}, {'word': 'label', 'entity': 'O'}, {'word': 'it', 'entity': 'O'}, {'word': 'as', 'entity': 'O'}, {'word': '“stateaffiliated,”', 'entity': 'O'}, {'word': 'which', 'entity': 'O'}, {'word': 'categorizes', 'entity': 'O'}, {'word': 'all', 'entity': 'O'}, {'word': '52', 'entity': 'O'}, {'word': 'NPRrun', 'entity': 'O'}, {'word': 'Twitter', 'entity': 'O'}, {'word': 'accounts', 'entity': 'O'}, {'word': 'as', 'entity': 'I-tim'}, {'word': 'propaganda', 'entity': 'O'}, {'word': 'channels.', 'entity': 'O'}, {'word': 'What', 'entity': 'B-org'}, {'word': 'do', 'entity': 'I-org'}, {'word': 'you', 'entity': 'B-org'}, {'word': 'think?', 'entity': 'I-geo'}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_ners(text:str) -> list:\n",
    "    output = []\n",
    "    B = np.asarray([tokenizer(text.replace(\"-\", \"\"))[\"input_ids\"]]).reshape(1,1,-1)\n",
    "    logits = model(torch.as_tensor(np.array(B))[0])[0]\n",
    "    for j in range(logits.shape[0]):\n",
    "        #print(logits[i])\n",
    "        logits_clean = logits[j].argmax(dim=1)\n",
    "        words = text.replace(\"-\", \"\").split()\n",
    "        #for i in range(len(eval(answer))-1):\n",
    "        #    print(words[i], eval(answer)[i])\n",
    "        i = 0\n",
    "        tokenized_sentence = ids_to_tokens(tokenizer(text.replace(\"-\", \"\"))[\"input_ids\"])\n",
    "        #print([ids_to_labels[x.item()] for x in logits_clean])\n",
    "        k = 0\n",
    "        for el in logits_clean:\n",
    "            if i == len(words):\n",
    "                break\n",
    "            elem = logits_clean[k]\n",
    "            if i+1 <= len(logits_clean) and tokenized_sentence[i][:2] == \"##\":\n",
    "                if elem.item() == \"O\":\n",
    "                    label = logits_clean[i]\n",
    "                else:\n",
    "                    label = elem.item()\n",
    "                output.append({\"word\":words[i], \"entity\":ids_to_labels[label]})\n",
    "                k+=2\n",
    "            else:\n",
    "                output.append({\"word\":words[i], \"entity\":ids_to_labels[elem.item()]})\n",
    "                k+=1\n",
    "            i += 1\n",
    "    return output\n",
    "print(get_ners(text))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-300')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def get_embeddings(list_of_tags: list):\n",
    "    emeddings = []\n",
    "    for tag in list_of_tags:\n",
    "        try:\n",
    "            #print(tokenizer.convert_ids_to_tokens(tokenizer(tag[\"word\"])[\"input_ids\"][1]))\n",
    "            embed = glove_vectors[tag[\"word\"]]\n",
    "            emeddings.append({'entity': tag[\"entity\"] , 'word': tag[\"word\"], \"embedding\": embed})\n",
    "        except:\n",
    "            pass\n",
    "    return emeddings\n",
    "def get_non_o(ner_words):\n",
    "    a = []\n",
    "    for x in ner_words:\n",
    "        if x[\"entity\"] != \"O\" :\n",
    "            a.append(x)\n",
    "    return a\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from collections import Counter\n",
    "\n",
    "def count_cos_embeddings(text_embeddings, anec_embeddings) -> (float, dict):\n",
    "    suitable_pairs = {0: []}\n",
    "    anec_unique_tags_counter = Counter()\n",
    "    embedding_cosine_sum = 0\n",
    "    for embedding in text_embeddings:\n",
    "        cosines = []\n",
    "        pair = \"\"\n",
    "        simmilarity_tags = {}\n",
    "        for embed in anec_embeddings:\n",
    "            anec_unique_tags_counter[embed[\"entity\"]] += 1\n",
    "            if embed[\"entity\"] == embedding[\"entity\"]:\n",
    "                v1 = embedding[\"embedding\"]\n",
    "                v2 = embed[\"embedding\"]\n",
    "                cos = np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "                cosines.append((cos, embed[\"word\"], embed[\"entity\"] ))\n",
    "        simmilarity_tags[embedding[\"word\"]] = cosines\n",
    "        suitable_pairs[0].append(simmilarity_tags)\n",
    "\n",
    "    top_similarity = {}\n",
    "    for key in suitable_pairs.keys():\n",
    "        for tag in anec_unique_tags_counter.keys():\n",
    "            for embed in anec_embeddings:\n",
    "                top_similarity[embed[\"word\"]] = (-10, \"\")\n",
    "            for word_dict in suitable_pairs[key]:\n",
    "                word = list(word_dict.keys())[0]\n",
    "                for sim in word_dict[word]:\n",
    "                    if top_similarity[sim[1]][0] < sim[0]:\n",
    "                        top_similarity[sim[1]] = (sim[0], word)\n",
    "    #print(top_similarity)\n",
    "    #print(suitable_pairs)\n",
    "    for key in top_similarity.keys():\n",
    "        embedding_cosine_sum += top_similarity[key][0]\n",
    "    embedding_cosine_sum /= len(top_similarity.keys()) if len(top_similarity.keys())>5 else 5\n",
    "    return embedding_cosine_sum, top_similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anec = english_anecs_list[3]\n",
    "text = texts[9][1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'B-org': 32, 'I-org': 8})\n",
      "{'walks': (0.27021483, 'you'), 'into': (0.46386227, 'to'), 'and': (0.53074193, 'to'), 'asks': (0.43194485, 'you'), 'any': (0.58032215, 'you')}\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.45541720390319823"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtred_anec = get_non_o(get_ners(anec))\n",
    "filtred_text = get_non_o(get_ners(text))\n",
    "anec_embeddings = get_embeddings(filtred_anec)\n",
    "text_embeddings = get_embeddings(filtred_text)\n",
    "count_cos_embeddings(text_embeddings, anec_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'I-org': 8, 'B-org': 8, 'B-geo': 8, 'B-tim': 8})\n",
      "Counter({'B-per': 8})\n",
      "Counter({'B-org': 16})\n",
      "Counter({'B-org': 32, 'I-org': 8})\n",
      "Counter({'B-tim': 16, 'I-tim': 16, 'B-geo': 8, 'B-org': 8, 'I-org': 8})\n",
      "Counter({'B-org': 32, 'B-geo': 24, 'I-org': 16, 'B-tim': 16, 'I-tim': 8})\n",
      "Counter()\n",
      "Counter({'B-tim': 32, 'B-org': 16, 'B-per': 16, 'I-per': 8, 'I-org': 8})\n",
      "Counter({'B-org': 56, 'B-per': 24, 'I-org': 16, 'B-gpe': 8})\n",
      "Counter({'B-org': 40, 'I-org': 32, 'B-geo': 32})\n",
      "Counter({'B-org': 16, 'I-org': 8})\n",
      "Counter({'B-geo': 8})\n",
      "Counter({'B-org': 40, 'I-org': 32, 'B-tim': 24, 'B-geo': 16, 'B-per': 8, 'I-per': 8, 'B-gpe': 8})\n",
      "Counter({'B-per': 8})\n",
      "Counter({'B-org': 64, 'I-org': 48, 'B-geo': 8, 'I-tim': 8})\n",
      "Counter({'B-org': 16, 'I-per': 16, 'B-per': 16, 'I-org': 16, 'B-tim': 8})\n",
      "A man running a little behind schedule arrives at a picture theatre, goes  in to watch the movie that has already started, and as his eyes adjust to  the darkness, he is surprised to see a dog sitting beside its master in  the row ahead, intently watching the movie.  It even seemed to be enjoying  the movie:  wagging its tail in the happy bits, drooping its ears at the  sad bits, and hiding its eyes with its paws at the scary bits.  After the  movie, the man approaches the dogs owner, \"Jeez mate, your dog really seemed to enjoy the movie.  I'm amazed!\" \"Yes, I'm amazed also,\" came the reply.  \"He hated the book.\"\n",
      "Counter({'I-org': 16})\n",
      "Counter({'B-geo': 8, 'I-org': 8})\n",
      "Counter({'B-org': 32, 'B-per': 16, 'B-geo': 8, 'B-tim': 8})\n",
      "Counter()\n",
      "Counter({'B-org': 64, 'I-org': 24})\n",
      "Counter({'I-per': 16})\n",
      "A guy is having marital problems. He and the wife are not    communicating at all and he's lonesome so he goes to a pet store    thinking a pet might help. The store he happened to walk into    specialized in parrots. As he wanders down the rows of parrots he    notices one with no feet. Surprised he mutters \"I wonder how he hangs    onto the perch?\" The parrot says \"With my prick, you dummy.\" The guy    is startled and says \"You certainly talk well for a parrot.\"    The parrot says \"Of course, I'm a very well educated parrot.    I can discuss politics, sports, religion, most any subject you wish.\"    The guy says \"Gee, you sound like just what I was looking for.\"    The parrot says \"There's not much of a market for maimed parrots.    If you offer the proprietor $20 for me I'll bet he'll sell me.\"    The guy buys the parrot and for three months things go great. When he    comes home from work the parrot tells him Clinton said this, the A's    won, the Giant's lost, the pope did so and so. One day the guy comes    home from work and the parrot waves a wing at him and says \"Come in    and shut the door.\" The guy says \"What's up?\"    The parrot says \"I don't know how to tell you this, but the mailman    came today. Your wife answered the door in her negligee and he kissed    her right on the lips.\"    The guy says \"Oh, A momentary flight of passion.\"    The parrot says \"Then he fondled her breasts.\" The guy says \"He    did??!\"    The parrot says \"Then he pulled her negligee down and started sucking    on her breasts.\"    The guy says \"My God, what happened next???!!!\"    The parrot says \"I don't know. I got a hard-on and fell off my perch.\"\n",
      "Counter({'I-org': 40, 'B-tim': 32, 'B-gpe': 24, 'B-org': 16, 'B-geo': 8})\n",
      "Counter({'B-gpe': 24})\n",
      "Counter({'B-org': 56, 'B-tim': 16, 'I-tim': 8, 'B-per': 8})\n",
      "Counter({'B-org': 56, 'I-org': 56, 'B-tim': 24, 'B-geo': 24, 'I-tim': 8})\n",
      "Counter()\n",
      "Counter({'B-org': 8, 'B-geo': 8})\n",
      "Dr. Cutter is the local Veterinarian, known for his wry humor.  He surpassed himself one summer day when a city dog was brought to him after an encounter with a porcupine.\n",
      "Counter({'B-per': 8})\n",
      "Counter({'B-geo': 24, 'B-org': 8})\n",
      "Counter({'B-org': 64, 'B-per': 40, 'I-org': 16, 'I-tim': 8, 'B-tim': 8, 'B-geo': 8})\n",
      "Counter({'B-org': 64, 'I-org': 24, 'B-geo': 8, 'I-tim': 8})\n",
      "Counter({'B-org': 24})\n",
      "Counter({'B-org': 8})\n",
      "Counter({'B-org': 8})\n",
      "Counter({'B-org': 48, 'I-org': 24})\n",
      "Counter({'B-geo': 8, 'B-org': 8})\n",
      "An old bloke in the Northern Territory was showing some tourists how to  top up a camel with water. \"That way,\" he said, \"You get an extra day out of them between drinks.\" As the camel bent down to drink, the bloke picked up two bricks and bashed  them over the camel's balls. The camel sucked in its breath and took on three days' extra water. \"Doesn't that hurt?\" asked a tourist. \"Nah,\" replied the bloke. \"Only if you get your fingers caught!\"\n",
      "Counter()\n",
      "Counter({'I-tim': 24, 'B-org': 16, 'B-geo': 16, 'I-org': 8})\n",
      "Counter()\n",
      "Counter({'B-org': 16, 'I-org': 8})\n",
      "Counter({'B-org': 16, 'B-geo': 8, 'I-org': 8, 'B-tim': 8})\n",
      "Counter()\n",
      "Counter({'B-per': 16, 'I-org': 8, 'B-geo': 8})\n",
      "Counter({'B-per': 48, 'I-per': 16, 'B-geo': 16, 'B-tim': 8, 'B-org': 8})\n",
      "Counter({'I-org': 16, 'B-geo': 16, 'B-org': 8})\n",
      "Counter()\n",
      "Counter()\n",
      "Counter({'I-org': 32, 'B-org': 16})\n",
      "Three dogs are sitting in the waiting room of a vets office. One is a poodle, one is a schnauzer and the other is a great Dane. The poodle turns to the schnauzer and asks \"why are you here?\" The schnauzer responds, \"I'm 17 years old. I don't see or hear very well. I've been having accidents in the house. My owner says I'm too old and sick so he brought me here to be put to sleep.\" The schnauzer asks the poodle \"why are you here?\" The poodle responds, \"I've not been myself lately. I've been especially high strung. I've been barking all the time, I've been snapping at people and I even bit one of the neighbor's kids. Nobody knows why this has been happening. My owner says he can't risk me biting somebody else so he brought me here to be put to sleep.\" The poodle and schnauzer ask the great Dane why he is here. The great Dane responds: \"My owner is this beautiful runway model. Yesterday she was walking around the house naked when she suddenly bent down to pick up something she dropped. She was bent over and naked when nature took over and the next thing I know I'm on top of her doing the doggie thing. I couldn't help myself. \" The poodle asks: \"so she brought you here to put to sleep?\" \"Oh, no...., I'm just here to get my nails trimmed.\"\n",
      "Laboratory Rabbit Freedom    A rabbit one day managed to break free from the laboratory where he    had been born and    brought up. As he scurried away from the fencing of the compound, he    felt grass under his    little feet and saw the dawn breaking for the first time in his life.    'Wow, this is great,' he    thought. It wasn't long before he came to a hedge and, after squeezing    under it he saw a    wonderful sight lots of other bunny rabbits, all free and nibbling at    the lush grass.    'Hey,' he called. 'I'm a rabbit from the laboratory and I've just    escaped. Are you wild    rabbits?    'Yes. Come and join us,' they cried.    Our friend hopped over to them and started eating the grass. It tasted    so good. 'What else    do you wild rabbits do?' he asked.    'Well,' one of them said. 'You see that field there? It's got carrots    growing in it. We dig    them up and eat them.'    This, he couldn't resist and he spent the next hour eating the most    succulent carrots. They    were wonderful.    Later, he asked them again, 'What else do you do?'    'You see that field there? It's got lettuce growing in it. We eat them    as well.'    The lettuce tasted just as good and he returned a while later    completely full. 'Is there    anything else you guys do?' he asked.    One of the other rabbits came a bit closer to him and spoke softly.    'There's one other thing    you must try. You see those rabbits there,' he said, pointing to the    far corner of the field.    'They're girls. We poke them. Go and try it.'    Well, our friend spent the rest of the morning screwing his little    heart out until, completely    knackered, he staggered back over to the guys.    'That was fantastic,' he panted.    'So are you going to live with us then?' one of them asked.    'I'm sorry, I had a great time but I can't.'    The wild rabbits all stared at him, a bit surprised. 'Why? We thought    you liked it here.'    'I do,' our friend replied. 'But I must get back to the laboratory.    I'm dying for a cigarette.'\n",
      "Counter()\n",
      "Counter({'I-org': 24, 'B-org': 16})\n",
      "Counter({'B-org': 40, 'B-per': 24})\n",
      "Counter()\n",
      "Counter({'B-org': 56, 'I-org': 8, 'B-geo': 8})\n",
      "Counter()\n",
      "Counter()\n",
      "Counter({'B-org': 8, 'I-org': 8})\n",
      "Counter({'B-geo': 8, 'B-per': 8, 'B-org': 8})\n",
      "Counter()\n",
      "Counter({'I-org': 24, 'B-org': 16, 'B-geo': 16})\n",
      "Counter({'B-geo': 8, 'I-geo': 8})\n",
      "A golf pro was helping this attractive young woman with her swing when    his zipper got caught in the rhinestones on the back of her skirt.    Needless to say this was embarrassing to both of them since their    relationship had been purely platonic.    They decided to walk together in this lock-step back to the clubhouse    where certainly a pair of needle-nosed pliers would fix the problem.    Just as they turned the corner to the clubhouse a German Shepherd ran    up and threw a bucket of water on them.\n",
      "Counter({'I-org': 72, 'B-org': 56, 'B-geo': 8, 'B-per': 8})\n",
      "Counter({'B-org': 16, 'I-org': 8, 'B-per': 8})\n",
      "Counter({'B-org': 8})\n",
      "Counter()\n",
      "Counter({'B-org': 40, 'B-per': 24})\n",
      "Counter({'B-geo': 8, 'I-geo': 8})\n",
      "Counter({'B-org': 40, 'I-org': 8, 'I-per': 8})\n",
      "Counter({'B-geo': 24, 'B-org': 16, 'I-org': 8, 'I-tim': 8})\n",
      "A mouse and a lion walk were in a bar, drinking a few beers when a    giraffe walked in.    \"Get a load of her\" said the mouse, \"what a babe!\" \"Well, why not try    your luck?\" replied    the lion. So the mouse went over to the giraffe and started talking to    her. Within five    minutes they're out the door and into the night. The next day, the    lion was drinking in the    bar, when the mouse staggered in. The mouse is completely worn out,    and can hardly hold    himself up. The lion helped his pal up on to a stool, poured a drink    down his throat and    said, \"What the hell happened to you? I saw you leave with the    giraffe, what happened    after that? Was she all right?\"    The mouse replied, \"Yeah, she was really something, we went out to    dinner, had a couple    of glasses of wine, and she invited me back to her place to spend the    night. And oh, man!    I've never had a night like it!\" \"But how come you look like you're so    exhausted?\" asked    the lion. \"Well\" said the mouse, \"between the kissing and the    screwing, I must have run a    thousand miles!\"\n",
      "Counter({'B-tim': 8, 'B-geo': 8, 'B-org': 8})\n",
      "Counter({'I-org': 72, 'B-org': 56, 'B-geo': 8, 'B-per': 8})\n",
      "A golf pro was helping this attractive young woman with her swing when    his zipper got caught in the rhinestones on the back of her skirt.    Needless to say this was embarrassing to both of them since their    relationship had been purely platonic.    They decided to walk together in this lock-step back to the clubhouse    where certainly a pair of needle-nosed pliers would fix the problem.    Just as they turned the corner to the clubhouse a German Shepherd ran    up and threw a bucket of water on them.\n",
      "Counter({'B-tim': 8})\n",
      "Counter({'B-org': 16, 'I-org': 8, 'B-per': 8})\n",
      "Counter({'B-org': 8})\n",
      "Counter({'B-org': 40, 'I-org': 40, 'B-tim': 16, 'I-geo': 8, 'B-geo': 8, 'B-gpe': 8})\n",
      "Counter()\n",
      "Counter({'B-geo': 8, 'B-per': 8, 'B-org': 8})\n",
      "Counter()\n",
      "Counter({'B-tim': 16, 'B-org': 16, 'B-geo': 16, 'I-tim': 8, 'I-org': 8})\n",
      "Counter({'B-org': 16, 'B-geo': 8, 'B-per': 8})\n",
      "Counter({'B-org': 8})\n",
      "Counter({'B-org': 48, 'I-org': 24, 'I-per': 8, 'B-per': 8})\n",
      "Counter({'B-org': 8, 'I-org': 8})\n",
      "Counter()\n",
      "A highly timid little man, ventured into a biker bar in the Bronx and clearing his throat asked, \"Um, err, which of you gentlemen owns the Doberman tied outside to the parking meter?\" A giant of a man, wearing biker leathers, his body hair growing out through the seams, turned slowly on his stool, looked down at the quivering little man and said, \"It's my dog. Why?\" \"Well,\" squeaked the little man, obviously very nervous, \"I believe my dog just killed it, sir.\" \"What?\" roared the big man in disbelief. \"What in the hell kind of dog do you have?\" \"Sir,\" answered the little man, \"It's a four week old puppy.\" \"Bull!\" roared the biker, \"How could your puppy kill my Doberman?\" \"It appears that he choked on it, sir.\"\n",
      "Counter({'B-geo': 8})\n",
      "Counter({'B-tim': 8, 'B-org': 8, 'I-org': 8})\n",
      "Counter({'B-tim': 8})\n",
      "Counter()\n",
      "Counter()\n",
      "Counter({'B-org': 16, 'I-org': 8})\n",
      "A little old lady buys a pair of parrots, but cannot identify their sexes.  She calls the shop, and the man there advises her to watch them carefully  and all would become clear in time. 0.5270818918943405 [{'word': 'plans', 'entity': 'B-org'}, {'word': 'to', 'entity': 'B-org'}, {'word': 'after', 'entity': 'B-org'}, {'word': 'decision', 'entity': 'I-org'}, {'word': 'to', 'entity': 'I-org'}, {'word': 'as', 'entity': 'I-tim'}, {'word': 'What', 'entity': 'B-org'}, {'word': 'do', 'entity': 'I-org'}, {'word': 'you', 'entity': 'B-org'}, {'word': 'think?', 'entity': 'I-geo'}] {'but': (0.65469766, 'do'), 'cannot': (0.667467, 'do'), 'there': (0.5987254, 'you'), 'advises': (0.22641517, 'do'), 'clear': (0.48810425, 'to')}\n"
     ]
    }
   ],
   "source": [
    "# anec_embeddings - pickle embeddings of all anecs\n",
    "best_anec = None\n",
    "best_cos = -10\n",
    "best_text_ner = None\n",
    "best_simmilarity = None\n",
    "for anec in english_anecs_list[0:100]:\n",
    "    try:\n",
    "        filtred_anec = get_non_o(get_ners(anec))\n",
    "        filtred_text = get_non_o(get_ners(text))\n",
    "        anec_embeddings = get_embeddings(filtred_anec)\n",
    "        text_embeddings = get_embeddings(filtred_text)\n",
    "        new_cosine, new_simmilarity = count_cos_embeddings(text_embeddings, anec_embeddings)\n",
    "        if new_cosine > best_cos:\n",
    "            best_cos = new_cosine\n",
    "            best_anec = anec\n",
    "            best_text_ner = get_non_o(get_ners(text))\n",
    "            best_simmilarity = new_simmilarity\n",
    "    except:\n",
    "        print(anec)\n",
    "print(best_anec,best_cos, best_text_ner, best_simmilarity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A little old lady buys a pair of parrots, do do identify their sexes. She calls the shop, and the man you do her to watch them carefully and all would become to in time.\n"
     ]
    }
   ],
   "source": [
    "words = best_anec.split()\n",
    "key_words = best_simmilarity.keys()\n",
    "for i in range(len(words)):\n",
    "    if words[i] in key_words:\n",
    "        words[i] = best_simmilarity[words[i]][1]\n",
    "resulted_text = \" \".join(words)\n",
    "print(resulted_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
