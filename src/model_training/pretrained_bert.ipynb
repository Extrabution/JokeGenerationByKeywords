{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of             Sentence #                                           Sentence  \\\n0          Sentence: 1  Thousands of demonstrators have marched throug...   \n1          Sentence: 2  Families of soldiers killed in the conflict jo...   \n2          Sentence: 3  They marched from the Houses of Parliament to ...   \n3          Sentence: 4  Police put the number of marchers at 10,000 wh...   \n4          Sentence: 5  The protest comes on the eve of the annual con...   \n...                ...                                                ...   \n47954  Sentence: 47955  Indian border security forces are accusing the...   \n47955  Sentence: 47956  Indian officials said no one was injured in Sa...   \n47956  Sentence: 47957  Two more landed in fields belonging to a nearb...   \n47957  Sentence: 47958  They say not all of the rockets exploded upon ...   \n47958  Sentence: 47959    Indian forces said they responded to the attack   \n\n                                                     POS  \\\n0      ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n1      ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...   \n2      ['PRP', 'VBD', 'IN', 'DT', 'NNS', 'IN', 'NN', ...   \n3      ['NNS', 'VBD', 'DT', 'NN', 'IN', 'NNS', 'IN', ...   \n4      ['DT', 'NN', 'VBZ', 'IN', 'DT', 'NN', 'IN', 'D...   \n...                                                  ...   \n47954  ['JJ', 'NN', 'NN', 'NNS', 'VBP', 'VBG', 'PRP$'...   \n47955  ['JJ', 'NNS', 'VBD', 'DT', 'NN', 'VBD', 'VBN',...   \n47956  ['CD', 'JJR', 'VBD', 'IN', 'NNS', 'VBG', 'TO',...   \n47957  ['PRP', 'VBP', 'RB', 'DT', 'IN', 'DT', 'NNS', ...   \n47958  ['JJ', 'NNS', 'VBD', 'PRP', 'VBD', 'TO', 'DT',...   \n\n                                                     Tag  \n0      ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...  \n1      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n2      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n3      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n4      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n...                                                  ...  \n47954  ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe...  \n47955  ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...  \n47956  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n47957  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n47958       ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O']  \n\n[47959 rows x 4 columns]>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.read_csv(\"../../data/ner.csv\")\n",
    "dataframe.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "unique_labels = set()\n",
    "label_counter = Counter()\n",
    "for list_of_tags in dataframe[\"Tag\"]:\n",
    "  for tag in eval(list_of_tags):\n",
    "    unique_labels.add(tag)\n",
    "    label_counter[tag] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 887908,\n",
      "         'B-geo': 37644,\n",
      "         'B-tim': 20333,\n",
      "         'B-org': 20143,\n",
      "         'I-per': 17251,\n",
      "         'B-per': 16990,\n",
      "         'I-org': 16784,\n",
      "         'B-gpe': 15870,\n",
      "         'I-geo': 7414,\n",
      "         'I-tim': 6528,\n",
      "         'B-art': 402,\n",
      "         'B-eve': 308,\n",
      "         'I-art': 297,\n",
      "         'I-eve': 253,\n",
      "         'B-nat': 201,\n",
      "         'I-gpe': 198,\n",
      "         'I-nat': 51})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(label_counter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-art': 0, 'B-eve': 1, 'B-geo': 2, 'B-gpe': 3, 'B-nat': 4, 'B-org': 5, 'B-per': 6, 'B-tim': 7, 'I-art': 8, 'I-eve': 9, 'I-geo': 10, 'I-gpe': 11, 'I-nat': 12, 'I-org': 13, 'I-per': 14, 'I-tim': 15, 'O': 16}\n"
     ]
    }
   ],
   "source": [
    "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
    "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n",
    "print(labels_to_ids)\n",
    "import pickle\n",
    "with open(\"../../data/ids_to_labels.pickle\", \"wb\") as f:\n",
    "    pickle.dump(ids_to_labels, f)\n",
    "with open(\"../../data/labels_to_ids.pickle\", \"wb\") as f:\n",
    "    pickle.dump(labels_to_ids, f)\n",
    "with open(\"../../data/unique_labels.pickle\", \"wb\") as f:\n",
    "    pickle.dump(unique_labels, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('dslim/bert-base-NER')\n",
    "\n",
    "def ids_to_tokens(input):\n",
    "    return tokenizer.convert_ids_to_tokens(input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def align_label(texts, labels):\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]])\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]] if True else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return label_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DataSequence(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        lb = df['Tag'].values.tolist()\n",
    "        txt = df['Sentence'].values.tolist()\n",
    "        self.texts = [tokenizer(str(i),\n",
    "                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt]\n",
    "        self.labels = [align_label(i,j) for i,j in zip(txt, lb)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_data(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        return torch.LongTensor(self.labels[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_data = self.get_batch_data(idx)\n",
    "        batch_labels = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_data, batch_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_train, df_val, df_test = np.split(dataframe[:100].sample(frac=1, random_state=42),\n",
    "                            [int(.8 * len(dataframe[:100])), int(.9 * len(dataframe[:100]))])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "\n",
    "class BertModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertModel, self).__init__()\n",
    "        self.bert = BertForTokenClassification.from_pretrained('dslim/bert-base-NER', num_labels=len(unique_labels), ignore_mismatched_sizes=True)\n",
    "\n",
    "    def forward(self,input_ids, label=None):\n",
    "        output = self.bert(labels=label, input_ids = input_ids, return_dict=False)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dslim/bert-base-NER and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([17, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([17]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model = BertModel()\n",
    "\n",
    "model.load_state_dict(torch.load('bert_trainedNEREnglish',map_location=torch.device('cpu')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      Sentence #                                           Sentence  \\\n91  Sentence: 92  Gunmen have shot and killed a Roman Catholic n...   \n74  Sentence: 75  Harcourt , of the Australian Trade Commission ...   \n86  Sentence: 87  Indonesian police have arrested three men in c...   \n82  Sentence: 83  In recent weeks , AU officials say Sudanese tr...   \n20  Sentence: 21  Local news reports said at least five mortar s...   \n60  Sentence: 61  They say the company has produced some shoddy ...   \n71  Sentence: 72  It was made a permanent body in 1995 to provid...   \n14  Sentence: 15  An official with the German firm Bilfinger Ber...   \n92  Sentence: 93  Some witnesses to the Sunday shooting said the...   \n51  Sentence: 52  A senior Pakistani military official says Paki...   \n\n                                                  POS  \\\n91  ['NNS', 'VBP', 'VBN', 'CC', 'VBN', 'DT', 'NNP'...   \n74  ['NNP', ',', 'IN', 'DT', 'NNP', 'NNP', 'NNP', ...   \n86  ['JJ', 'NNS', 'VBP', 'VBN', 'CD', 'NNS', 'IN',...   \n82  ['IN', 'JJ', 'NNS', ',', 'NNP', 'NNS', 'VBP', ...   \n20  ['JJ', 'NN', 'NNS', 'VBD', 'IN', 'JJS', 'CD', ...   \n60  ['PRP', 'VBP', 'DT', 'NN', 'VBZ', 'VBN', 'DT',...   \n71  ['PRP', 'VBD', 'VBN', 'DT', 'JJ', 'NN', 'IN', ...   \n14  ['DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'N...   \n92  ['DT', 'NNS', 'TO', 'DT', 'NNP', 'NN', 'VBD', ...   \n51  ['DT', 'JJ', 'JJ', 'JJ', 'NN', 'VBZ', 'NNP', '...   \n\n                                                  Tag  \n91  ['O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'I-org...  \n74  ['B-per', 'O', 'O', 'O', 'B-org', 'I-org', 'I-...  \n86  ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...  \n82  ['O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'B-gpe...  \n20  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n60  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n71  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', '...  \n14  ['O', 'O', 'O', 'O', 'B-gpe', 'O', 'B-org', 'I...  \n92  ['O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', '...  \n51  ['O', 'O', 'B-gpe', 'O', 'O', 'O', 'B-gpe', 'O...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Sentence</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>91</th>\n      <td>Sentence: 92</td>\n      <td>Gunmen have shot and killed a Roman Catholic n...</td>\n      <td>['NNS', 'VBP', 'VBN', 'CC', 'VBN', 'DT', 'NNP'...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-org', 'I-org...</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Sentence: 75</td>\n      <td>Harcourt , of the Australian Trade Commission ...</td>\n      <td>['NNP', ',', 'IN', 'DT', 'NNP', 'NNP', 'NNP', ...</td>\n      <td>['B-per', 'O', 'O', 'O', 'B-org', 'I-org', 'I-...</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>Sentence: 87</td>\n      <td>Indonesian police have arrested three men in c...</td>\n      <td>['JJ', 'NNS', 'VBP', 'VBN', 'CD', 'NNS', 'IN',...</td>\n      <td>['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '...</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Sentence: 83</td>\n      <td>In recent weeks , AU officials say Sudanese tr...</td>\n      <td>['IN', 'JJ', 'NNS', ',', 'NNP', 'NNS', 'VBP', ...</td>\n      <td>['O', 'O', 'O', 'O', 'B-org', 'O', 'O', 'B-gpe...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Sentence: 21</td>\n      <td>Local news reports said at least five mortar s...</td>\n      <td>['JJ', 'NN', 'NNS', 'VBD', 'IN', 'JJS', 'CD', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Sentence: 61</td>\n      <td>They say the company has produced some shoddy ...</td>\n      <td>['PRP', 'VBP', 'DT', 'NN', 'VBZ', 'VBN', 'DT',...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>Sentence: 72</td>\n      <td>It was made a permanent body in 1995 to provid...</td>\n      <td>['PRP', 'VBD', 'VBN', 'DT', 'JJ', 'NN', 'IN', ...</td>\n      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', '...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Sentence: 15</td>\n      <td>An official with the German firm Bilfinger Ber...</td>\n      <td>['DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'N...</td>\n      <td>['O', 'O', 'O', 'O', 'B-gpe', 'O', 'B-org', 'I...</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>Sentence: 93</td>\n      <td>Some witnesses to the Sunday shooting said the...</td>\n      <td>['DT', 'NNS', 'TO', 'DT', 'NNP', 'NN', 'VBD', ...</td>\n      <td>['O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', '...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>Sentence: 52</td>\n      <td>A senior Pakistani military official says Paki...</td>\n      <td>['DT', 'JJ', 'JJ', 'JJ', 'NN', 'VBZ', 'NNP', '...</td>\n      <td>['O', 'O', 'B-gpe', 'O', 'O', 'O', 'B-gpe', 'O...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 34, 17])\n",
      "tensor([16, 16, 16, 16, 16, 16, 16, 16,  3,  3, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16,  2,  2,  2,  2,  2, 10, 10, 10, 10, 16,  2, 16, 16])\n",
      "[('Gunmen', 'O', 'O'), ('have', 'O', 'O'), ('shot', 'O', 'O'), ('and', 'O', 'O'), ('killed', 'O', 'O'), ('a', 'O', 'O'), ('Roman', 'O', 'B-org'), ('Catholic', 'B-gpe', 'I-org'), ('nun', 'B-gpe', 'O'), ('and', 'O', 'O'), ('her', 'O', 'O'), ('bodyguard', 'O', 'O'), ('at', 'O', 'O'), ('the', 'O', 'O'), ('hospital', 'O', 'O'), ('where', 'O', 'O'), ('she', 'O', 'O'), ('worked', 'O', 'O'), ('in', 'O', 'O'), ('Islamistcontrolled', 'O', 'O'), ('Mogadishu', 'B-geo', 'B-geo'), (',', 'B-geo', 'O'), ('Somalia', 'B-geo', 'B-geo'), ('.', 'B-geo', 'O')]\n",
      "torch.Size([1, 24, 17])\n",
      "tensor([16,  6, 16, 16, 16,  5, 13, 13, 16, 16, 16,  5,  5, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16])\n",
      "[('Gunmen', 'O', 'O'), ('have', 'O', 'O'), ('shot', 'O', 'O'), ('and', 'O', 'O'), ('killed', 'O', 'O'), ('a', 'O', 'O'), ('Roman', 'O', 'B-org'), ('Catholic', 'B-gpe', 'I-org'), ('nun', 'B-gpe', 'O'), ('and', 'O', 'O'), ('her', 'O', 'O'), ('bodyguard', 'O', 'O'), ('at', 'O', 'O'), ('the', 'O', 'O'), ('hospital', 'O', 'O'), ('where', 'O', 'O'), ('she', 'O', 'O'), ('worked', 'O', 'O'), ('in', 'O', 'O'), ('Islamistcontrolled', 'O', 'O'), ('Mogadishu', 'B-geo', 'B-geo'), (',', 'B-geo', 'O'), ('Somalia', 'B-geo', 'B-geo'), ('.', 'B-geo', 'O'), ('Harcourt', 'O', 'B-per'), (',', 'B-per', 'O'), ('of', 'O', 'O'), ('the', 'O', 'O'), ('Australian', 'O', 'B-org'), ('Trade', 'B-org', 'I-org'), ('Commission', 'I-org', 'I-org'), (',', 'I-org', 'O'), ('says', 'O', 'O'), ('the', 'O', 'O'), ('ABAC', 'O', 'B-org'), ('report', 'B-org', 'O'), ('will', 'B-org', 'O'), ('also', 'O', 'O'), ('discuss', 'O', 'O'), ('ways', 'O', 'O'), ('to', 'O', 'O'), ('enhance', 'O', 'O'), ('regional', 'O', 'O'), ('cooperation', 'O', 'O'), ('.', 'O', 'O')]\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "j = 0\n",
    "for sentence, answer in zip(df_test[\"Sentence\"], df_test[\"Tag\"]):\n",
    "    B = np.asarray([tokenizer(sentence.replace(\"-\", \"\"))[\"input_ids\"]]).reshape(1,1,-1)\n",
    "    logits = model(torch.as_tensor(np.array(B))[0])[0]\n",
    "    print(logits.shape)\n",
    "    for i in range(logits.shape[0]):\n",
    "        #print(logits[i])\n",
    "        logits_clean = logits[i].argmax(dim=1)\n",
    "        words = sentence.replace(\"-\", \"\").split()\n",
    "        print(logits_clean)\n",
    "        #for i in range(len(eval(answer))-1):\n",
    "        #    print(words[i], eval(answer)[i])\n",
    "        i = 0\n",
    "        tokenized_sentence = ids_to_tokens(tokenizer(sentence.replace(\"-\", \"\"))[\"input_ids\"])\n",
    "        #print([ids_to_labels[x.item()] for x in logits_clean])\n",
    "        k = 0\n",
    "        for el in logits_clean[1:-1]:\n",
    "            if i == len(words):\n",
    "                break\n",
    "            elem = logits_clean[k]\n",
    "            if i+1 <= len(logits_clean) and tokenized_sentence[i][:2] == \"##\":\n",
    "                if elem.item() == \"O\":\n",
    "                    label = logits_clean[i]\n",
    "                else:\n",
    "                    label = elem.item()\n",
    "                output.append((words[i], ids_to_labels[label], eval(answer)[i]))\n",
    "                k+=2\n",
    "            else:\n",
    "                output.append((words[i], ids_to_labels[elem.item()], eval(answer)[i]))\n",
    "                k+=1\n",
    "            i += 1\n",
    "\n",
    "    print(output)\n",
    "    j+=1\n",
    "    if j == 2:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
