{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164ab8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4164ab8e",
    "outputId": "99adea57-2fa4-44c6-b028-d66f896c707f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "#!pip install torch\n",
    "#!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "#from torch.utils import data\n",
    "#rom pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering, BertForPreTraining ,BertAdam\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoConfig,\n",
    "    Trainer,\n",
    "    AutoTokenizer,\n",
    "    TextDataset,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments\n",
    ")\n",
    "import pandas as pd"
   ],
   "metadata": {
    "id": "2b65kdxX6NpZ"
   },
   "id": "2b65kdxX6NpZ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = 'bert-base-cased'\n",
    "\n",
    "name = f'{model_name}-title-comment'\n",
    "#if IN_COLAB:\n",
    "  #  !pip install transformers\n",
    " #   model_filename = f'/content/drive/MyDrive/Google colabs/{name}.pt'\n",
    "#else:\n",
    "model_filename = f'{name}.pt' # for when saving model to file"
   ],
   "metadata": {
    "id": "v5uy6U7E7ixv"
   },
   "id": "v5uy6U7E7ixv",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2935d",
   "metadata": {
    "id": "a7f2935d"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"article_texts.txt\",'rb')\n",
    "texts = pickle.load(f, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3982df",
   "metadata": {
    "id": "bb3982df"
   },
   "outputs": [],
   "source": [
    "titles = []\n",
    "comments = []\n",
    "for text in texts:\n",
    "    for i in range(len(text[2])):\n",
    "        titles.append(text[0])\n",
    "        comments.append(text[2][i][0])\n",
    "        \n",
    "zipped = list(zip(titles, comments))\n",
    "        \n",
    "df = pd.DataFrame(zipped, columns=['Title', 'Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293a6b0",
   "metadata": {
    "id": "d293a6b0"
   },
   "outputs": [],
   "source": [
    "test_set = df.sample(n = 500)\n",
    "df = df.loc[~df.index.isin(test_set.index)]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "separator = '[SEP]'"
   ],
   "metadata": {
    "id": "0HanUxfE70U6"
   },
   "id": "0HanUxfE70U6",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CommentsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, n=-1, max_length=1024):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.comments = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "          self.comments.append(\n",
    "                self.tokenizer.encode(f\"[CLS]{row['Title']}{separator}{row['Comment']}{separator}\")\n",
    "            )\n",
    "                \n",
    "        if n != -1:\n",
    "            self.comments = self.comments[:n]\n",
    "        self.comments_count = len(self.comments)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.comments_count\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.comments[item]"
   ],
   "metadata": {
    "id": "GY55IA7P6D0r"
   },
   "id": "GY55IA7P6D0r",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = CommentsDataset(tokenizer)"
   ],
   "metadata": {
    "id": "Z_ian5LKMG6V"
   },
   "id": "Z_ian5LKMG6V",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def modelTrainer (text_path, epochs=10, model_name='gpt2', batch_size=8, cache_dir='cache'):\n",
    "    model = AutoModelForCausalLM.from_pretrained (model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    data_collator = DataCollatorForLanguageModeling (tokenizer=tokenizer, mlm=False) \n",
    "    train_dataset = CommentsDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        n = 5000,\n",
    "    )\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=text_path,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        warmup_steps=500,\n",
    "        #save_steps=2000\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_dataset\n",
    "    )\n",
    "        \n",
    "    trainer.train()\n",
    "    trainer.save_model()"
   ],
   "metadata": {
    "id": "k4BFTs4S5Y3s"
   },
   "id": "k4BFTs4S5Y3s",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "modelTrainer(model_filename, epochs=20, model_name=model_name)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "id": "cQ7rfHCz63JV",
    "outputId": "31102151-f899-4b99-8bd9-8312afb5054c"
   },
   "id": "cQ7rfHCz63JV",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 27:11, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.065100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.044800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.040600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.038200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"bert-base-cased-title-comment.pt\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1BKABFGtCkXT",
    "outputId": "aebf79dd-0a83-497b-f279-35c66f199b2f"
   },
   "id": "1BKABFGtCkXT",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c4895",
   "metadata": {
    "id": "8c7c4895"
   },
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea9582",
   "metadata": {
    "id": "bcea9582"
   },
   "outputs": [],
   "source": [
    "def gen(title):\n",
    "    return generator(f\"{title}[SEP]\", max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d54098",
   "metadata": {
    "id": "c6d54098"
   },
   "outputs": [],
   "source": [
    "text = gen(\"[CLS]Putin to fight Trump WWE style[SEP]\")[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58330b",
   "metadata": {
    "id": "fd58330b"
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    return text.split('[SEP]')[0]"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAPTAvy7JCxC",
    "outputId": "20b6c6e9-0d4b-4dd9-ffd0-a82658b1b155"
   },
   "id": "mAPTAvy7JCxC",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<s>[CLS]Putin to fight Trump WWE style[SEP] “ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 147
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "clean(text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "KML5G1LXI1Ok",
    "outputId": "4002822b-36c9-4bf8-bd12-89f78452c5b1"
   },
   "id": "KML5G1LXI1Ok",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’ ’'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 95
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
